{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# ^^^ pyforest auto-imports - don't write above this line\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# importing linear support vector classifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2,3)] # Petal length, width\n",
    "y = (iris['target']==2).astype(np.float64) # Iris virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linear_svc', LinearSVC(C=1, loss='hinge'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('linear_svc', LinearSVC(C=1, loss='hinge'))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlike Logistic Regression classifiers, SVM classifiers do not output\n",
    "# probabilities for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of using the LinearSVC class, we could use the SVC class with a linear kernel.\n",
    "# When creating the SVC model, we would write SVC(kernel=\"linear\", C=1). Or we\n",
    "# could use the SGDClassifier class, with SGDClassifier(loss=\"hinge\", alpha=1/\n",
    "# (m*C)). This applies regular Stochastic Gradient Descent to train a\n",
    "# linear SVM classifier. It does not converge as fast as the LinearSVC class, but it can be\n",
    "# useful to handle online classification tasks or huge datasets that do not fit in memory\n",
    "# (out-of-core training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The LinearSVC class regularizes the bias term, so you should center\n",
    "# the training set first by subtracting its mean. This is automatic if\n",
    "# you scale the data using the StandardScaler. Also make sure you\n",
    "# set the loss hyperparameter to \"hinge\", as it is not the default\n",
    "# value. Finally, for better performance, you should set the dual\n",
    "# hyperparameter to False, unless there are more features than\n",
    "# training instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NONLINEAR SVM CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('poly_features', PolynomialFeatures(degree=3)),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('svm_clf', LinearSVC(C=10, loss='hinge'))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_moons(n_samples = 100, noise = 0.15)\n",
    "polynomial_svm_clf = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=3)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf', LinearSVC(C=10, loss='hinge'))\n",
    "])\n",
    "\n",
    "polynomial_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POLYNOMIAL KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svm_clf', SVC(C=5, coef0=1, kernel='poly'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "poly_kernel_svm_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf' ,SVC(kernel = \"poly\", degree = 3, coef0=1, C=5))\n",
    "])\n",
    "# The hyperparameter coef0 controls how much \n",
    "# the model is influenced by highdegree\n",
    "# polynomials versus low-degree polynomials.\n",
    "poly_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAUSSIAN RBF KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svm_clf', SVC(C=0.001, gamma=5))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_kernel_svm_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf', SVC(kernel='rbf', gamma=5, C=0.001))\n",
    "])\n",
    "rbf_kernel_svm_clf.fit(X, y)\n",
    "# Gamma acts like a regularization parameter, as well as C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
