{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOTING CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples = 100, noise = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()),\n",
       "                             ('svc', SVC(probability=True))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "                estimators=[('lr',log_clf),('rf',rnd_clf),('svc',svm_clf)],\n",
    "                voting='soft')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.88\n",
      "RandomForestClassifier 0.92\n",
      "SVC 0.96\n",
      "VotingClassifier 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAGGING AND PASTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the same algorithm on different random subsets of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when sampling is performed with replacement, this method is called bagging\n",
    "# (short for bootstrap), when sampling is performed without replacement, it is\n",
    "# called pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=0.1, bootstrap=True, n_jobs=-1)\n",
    "# n_jobs=-1 tells scikit-learn to use all available cores\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_samples can alternatively be set to a float between 0.0 and 1.0, in which case the max number of instances\n",
    "# to sample is equal to the size of the training set times max_samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUT OF BAG EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With bagging, some instances may be sampled several times for any given predictor,\n",
    "# while others may not be sampled at all. By default a BaggingClassifier samples m\n",
    "# training instances with replacement (bootstrap=True), where m is the size of the\n",
    "# training set. This means that only about 63% of the training instances are sampled on\n",
    "# average for each predictor. The remaining 37% of the training instances that are not\n",
    "# sampled are called out-of-bag (oob) instances. Note that they are not the same 37%\n",
    "# for all predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since a predictor never sees the oob instances during training, it can be evaluated on\n",
    "# these instances, without the need for a separate validation set. You can evaluate the\n",
    "# ensemble itself by averaging out the oob evaluations of each predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Scikit-Learn, you can set oob_score=True when creating a BaggingClassifier to\n",
    "# request an automatic oob evaluation after training. The following code demonstrates\n",
    "# this. The resulting evaluation score is available through the oob_score_ variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                           n_estimators=500,\n",
    "                           bootstrap=True,\n",
    "                           n_jobs=-1,\n",
    "                           oob_score=True)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97883598, 0.02116402],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07222222, 0.92777778],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.5027933 , 0.4972067 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00537634, 0.99462366],\n",
       "       [0.        , 1.        ],\n",
       "       [0.55445545, 0.44554455],\n",
       "       [0.41530055, 0.58469945],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99447514, 0.00552486],\n",
       "       [0.97512438, 0.02487562],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0052356 , 0.9947644 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.27717391, 0.72282609],\n",
       "       [0.79411765, 0.20588235],\n",
       "       [0.01111111, 0.98888889],\n",
       "       [0.96855346, 0.03144654],\n",
       "       [0.43814433, 0.56185567],\n",
       "       [0.91860465, 0.08139535],\n",
       "       [0.97814208, 0.02185792],\n",
       "       [0.03108808, 0.96891192],\n",
       "       [0.95135135, 0.04864865],\n",
       "       [0.94382022, 0.05617978],\n",
       "       [1.        , 0.        ],\n",
       "       [0.97484277, 0.02515723],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.93604651, 0.06395349],\n",
       "       [0.98421053, 0.01578947],\n",
       "       [0.        , 1.        ],\n",
       "       [0.12179487, 0.87820513],\n",
       "       [0.99418605, 0.00581395],\n",
       "       [0.04568528, 0.95431472],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.04864865, 0.95135135],\n",
       "       [0.52604167, 0.47395833],\n",
       "       [0.97191011, 0.02808989],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.9       , 0.1       ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.71921182, 0.28078818],\n",
       "       [0.60989011, 0.39010989],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98477157, 0.01522843],\n",
       "       [0.92432432, 0.07567568],\n",
       "       [0.1402439 , 0.8597561 ],\n",
       "       [0.66489362, 0.33510638],\n",
       "       [0.20879121, 0.79120879],\n",
       "       [0.25668449, 0.74331551],\n",
       "       [1.        , 0.        ],\n",
       "       [0.06703911, 0.93296089],\n",
       "       [0.98369565, 0.01630435],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99390244, 0.00609756],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00606061, 0.99393939],\n",
       "       [0.11731844, 0.88268156],\n",
       "       [0.22222222, 0.77777778],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.91758242, 0.08241758]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The oob decision function for each training instance is also available through the\n",
    "# oob_decision_function_ variable. In this case (since the base estimator has a pre\n",
    "# dict_proba() method), the decision function returns the class probabilities for each\n",
    "# training instance. For example, the oob evaluation estimates that the first training\n",
    "# instance has a 68.25% probability of belonging to the positive class (and 31.75% of\n",
    "# belonging to the negative class):\n",
    "\n",
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM PATCHES AND RANDOM SUBSPACES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The BaggingClassifier class supports sampling the features as well. Sampling is\n",
    "# controlled by two hyperparameters: max_features and bootstrap_features. They\n",
    "# work the same way as max_samples and bootstrap, but for feature sampling instead\n",
    "# of instance sampling. Thus, each predictor will be trained on a random subset of the\n",
    "# input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This technique is particularly useful when you are dealing with high-dimensional\n",
    "# inputs (such as images). Sampling both training instances and features is called the\n",
    "# Random Patches method. Keeping all training instances (by setting bootstrap=False\n",
    "# and max_samples=1.0) but sampling features (by setting bootstrap_features to\n",
    "# True and/or max_features to a value smaller than 1.0) is called the Random Subspaces\n",
    "# method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FORESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Score 0.92\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Score\", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a few exceptions, a RandomForestClassifier has all the hyperparameters of a\n",
    "# DecisionTreeClassifier (to control how trees are grown), plus all the hyperparameters\n",
    "# of a BaggingClassifier to control the ensemble itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
