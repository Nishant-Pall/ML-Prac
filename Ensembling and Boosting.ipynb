{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOTING CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples = 100, noise = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()),\n",
       "                             ('svc', SVC(probability=True))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "                estimators=[('lr',log_clf),('rf',rnd_clf),('svc',svm_clf)],\n",
    "                voting='soft')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.76\n",
      "RandomForestClassifier 0.92\n",
      "SVC 0.88\n",
      "VotingClassifier 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAGGING AND PASTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the same algorithm on different random subsets of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when sampling is performed with replacement, this method is called bagging\n",
    "# (short for bootstrap), when sampling is performed without replacement, it is\n",
    "# called pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=0.1, bootstrap=True, n_jobs=-1)\n",
    "# n_jobs=-1 tells scikit-learn to use all available cores\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_samples can alternatively be set to a float between 0.0 and 1.0, in which case the max number of instances\n",
    "# to sample is equal to the size of the training set times max_samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUT OF BAG EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With bagging, some instances may be sampled several times for any given predictor,\n",
    "# while others may not be sampled at all. By default a BaggingClassifier samples m\n",
    "# training instances with replacement (bootstrap=True), where m is the size of the\n",
    "# training set. This means that only about 63% of the training instances are sampled on\n",
    "# average for each predictor. The remaining 37% of the training instances that are not\n",
    "# sampled are called out-of-bag (oob) instances. Note that they are not the same 37%\n",
    "# for all predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since a predictor never sees the oob instances during training, it can be evaluated on\n",
    "# these instances, without the need for a separate validation set. You can evaluate the\n",
    "# ensemble itself by averaging out the oob evaluations of each predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Scikit-Learn, you can set oob_score=True when creating a BaggingClassifier to\n",
    "# request an automatic oob evaluation after training. The following code demonstrates\n",
    "# this. The resulting evaluation score is available through the oob_score_ variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                           n_estimators=500,\n",
    "                           bootstrap=True,\n",
    "                           n_jobs=-1,\n",
    "                           oob_score=True)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31052632, 0.68947368],\n",
       "       [0.56914894, 0.43085106],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.91428571, 0.08571429],\n",
       "       [0.00543478, 0.99456522],\n",
       "       [0.11764706, 0.88235294],\n",
       "       [0.66292135, 0.33707865],\n",
       "       [0.9895288 , 0.0104712 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.10344828, 0.89655172],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.2849162 , 0.7150838 ],\n",
       "       [0.24858757, 0.75141243],\n",
       "       [0.27118644, 0.72881356],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [0.07407407, 0.92592593],\n",
       "       [0.95263158, 0.04736842],\n",
       "       [0.43      , 0.57      ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01129944, 0.98870056],\n",
       "       [0.82022472, 0.17977528],\n",
       "       [0.11627907, 0.88372093],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00606061, 0.99393939],\n",
       "       [0.88135593, 0.11864407],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03804348, 0.96195652],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94350282, 0.05649718],\n",
       "       [1.        , 0.        ],\n",
       "       [0.84946237, 0.15053763],\n",
       "       [0.31884058, 0.68115942],\n",
       "       [0.0052356 , 0.9947644 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02162162, 0.97837838],\n",
       "       [0.98924731, 0.01075269],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99447514, 0.00552486],\n",
       "       [0.03589744, 0.96410256],\n",
       "       [0.87765957, 0.12234043],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99411765, 0.00588235],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.24352332, 0.75647668],\n",
       "       [0.78142077, 0.21857923],\n",
       "       [0.58100559, 0.41899441],\n",
       "       [0.6416185 , 0.3583815 ],\n",
       "       [0.83414634, 0.16585366],\n",
       "       [0.39790576, 0.60209424],\n",
       "       [0.0952381 , 0.9047619 ],\n",
       "       [0.79393939, 0.20606061],\n",
       "       [0.99431818, 0.00568182],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00961538, 0.99038462],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99494949, 0.00505051],\n",
       "       [0.1910828 , 0.8089172 ],\n",
       "       [0.74331551, 0.25668449],\n",
       "       [0.92820513, 0.07179487],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01595745, 0.98404255],\n",
       "       [0.4519774 , 0.5480226 ],\n",
       "       [0.28648649, 0.71351351],\n",
       "       [1.        , 0.        ],\n",
       "       [0.18518519, 0.81481481],\n",
       "       [1.        , 0.        ],\n",
       "       [0.29787234, 0.70212766]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The oob decision function for each training instance is also available through the\n",
    "# oob_decision_function_ variable. In this case (since the base estimator has a pre\n",
    "# dict_proba() method), the decision function returns the class probabilities for each\n",
    "# training instance. For example, the oob evaluation estimates that the first training\n",
    "# instance has a 68.25% probability of belonging to the positive class (and 31.75% of\n",
    "# belonging to the negative class):\n",
    "\n",
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM PATCHES AND RANDOM SUBSPACES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The BaggingClassifier class supports sampling the features as well. Sampling is\n",
    "# controlled by two hyperparameters: max_features and bootstrap_features. They\n",
    "# work the same way as max_samples and bootstrap, but for feature sampling instead\n",
    "# of instance sampling. Thus, each predictor will be trained on a random subset of the\n",
    "# input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This technique is particularly useful when you are dealing with high-dimensional\n",
    "# inputs (such as images). Sampling both training instances and features is called the\n",
    "# Random Patches method. Keeping all training instances (by setting bootstrap=False\n",
    "# and max_samples=1.0) but sampling features (by setting bootstrap_features to\n",
    "# True and/or max_features to a value smaller than 1.0) is called the Random Subspaces\n",
    "# method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
